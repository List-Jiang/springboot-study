server:
  port: 8080
  servlet:
    context-path:

spring:
  devtools:
    restart:
      enabled: true
      additional-paths: src/main/java
  security:
    user:
      name: user
      password: password
      roles: SWAGGER,ACTUATOR
  datasource:
    dynamic:
      primary: master
      strict: true
      datasource:
        master:
          driver-class-name: com.mysql.cj.jdbc.Driver
          url: jdbc:mysql://localhost:3306/test
          # url: jdbc:h2:mem:test
          username: sa
          password: sa
    #url: jdbc:mysql://localhost:3306/test
    #url: jdbc:h2:~/test
    #driver-class-name: org.h2.Driver
    #username: sa
    #password: sa
    #type: com.zaxxer.hikari.HikariDataSource
  #    driver-class-name: com.mysql.cj.jdbc.Driver
  #    url: jdbc:mysql://localhost:3306/test
  #    # url: jdbc:h2:mem:test
  #    username: sa
  #    password: sa
  #  driver-class-name: org.h2.Driver
  h2:
    console:
      enabled: true
      path: /h2-console
      settings.trace: false
      settings.web-allow-others: false
  #　TODO: 数据库初始化有问题，好像只能在jpa或jdbc上使用。先暂时注释
  sql:
    init:
      username: sa
      password: sa
      schema-locations: classpath:sql/schema.sql
      data-locations: classpath:sql/data.sql
      mode: never
  servlet:
    multipart:
      enabled: true
      max-file-size: 3MB
      max-request-size: 3MB
  thymeleaf:
    encoding: utf-8
    suffix: .html
    servlet:
      content-type: text/html
    mode: HTML
  application:
    name: springboot_study
  mvc:
    view:
      prefix: /
      suffix: .jsp
  resource:
    static-locations: classpath:/static/,classpath:/public/
  # kafka配置，这里关闭。必须关闭所有引入了kafka配置空间下的key-value的bean
  data:
    redis:
      lettuce:
        pool:
          max-active: 8   #最大连接数据库连接数,设 0 为没有限制
          max-idle: 8     #最大等待连接中的数量,设 0 为没有限制
          max-wait: -1ms  #最大建立连接等待时间。如果超过此时间将接到异常。设为-1表示无限制。
          min-idle: 0     #最小等待连接中的数量,设 0 为没有限制
        shutdown-timeout: 100ms
      database: 0
      password:
      username:
      url: redis://localhost:6379
#  kafka:
#    # Kafka集群
#    bootstrap-servers: 172.165.165.101:9092,172.165.165.102:9092,172.165.165.103:9092
#    # Kafka生产者配置
#    producer:
#      # 重试次数
#      retries: 2
#      # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
#      # 0：不等待返回的acks（可能会丢数据，因为发送消息没有了失败重试机制，但是这是最低延迟）
#      # 1：消息发送给kafka分区中的leader后就返回（如果follower没有同步完成leader就宕机了，就会丢数据）
#      # -1（默认）：等待所有follower同步完消息后再发送（绝对不会丢数据）
#      acks: 1
#      # 消息累计到batch-size的值后，才会发送消息，默认为16384
#      batch-size: 16384
#      properties:
#        # 提交延时：2ms,当消息累计一直没到batch-size的值。过了这个时间就发送消息。
#        linger.ms: 2
#      # 生产端内存缓冲区大小
#      buffer-memory: 33554432
#      #k afka序列化类配置
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer
#    # kafka消费者配置
#    consumer:
#      # 配置默认消费者分组id
#      group-id: defaultConsumerGroup
#      # 启动自动提交
#      enable-auto-commit: true
#      # 自动提交间隔
#      auto-commit-interval: 100ms
#      # kafka意外宕机时，再次开启消息消费的策略，共有三种策略
#      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
#      # earliest:重置为分区中最小的offset;（即从最早的未消费过的开始消费）
#      # latest:重置为分区中最新的offset（消费分区中新产生的数据，即从现在最新产生的开始消费。存在丢失数据风险）;
#      # none:只要有一个分区不存在已提交的offset,就抛出异常;
#      auto-offset-reset: earliest
#      #kafka反序列化类配置
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      #消费者单次取最大消费数
#      max-poll-records: 20
#    # kafka监听器配置
#    listener:
#      # 监听topics不存在是否无法启动项目
#      missing-topics-fatal: false
#      # 消费方式：single，单一消费；batch,批次消费
#      type: single
#    topic:
#      group-id: kafkaGroup1
#      toipic-name:
#        - topic1
#        - topic2
#        - topic3
mybatis-plus:
  mapper-locations: classpath:mapping/*.xml
  global-config:
    db-config:
      #全局逻辑删除字段名，实体配置了 @TableLogic 则以实体的为准，未配置则默认 status 为逻辑删除字段
      logic-delete-field: status
      #逻辑删除值 0
      logic-delete-value: 0
      #逻辑未删除值 1
      logic-not-delete-value: 1
  #通用枚举类扫描 支持统配符 * 或者 ; 分割
  configuration:
    #打印 sql
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
#自定义参数配置
custom:
  customValue1: 测试参数1
  # value注解 map案例,外面的双引号可用可不用
  map: "{ds: '发送失败',ds3: '未发送,ds4: 发送成功'}"
  # value注解 list使用案例,外面的双引号可用可不用
  list1: "test,test32"
  # ConfigurationProperties注解 搭配使用案例
  #配置简单请求路径，需要搭建自己的处理器，该配置方式必须有使用 ConfigurationProperties注解 的参数配置类引入，好像不可以使用 value注解 解析
  simple-view-controllers:
    - urlParame: index
      templatePath: index
    - urlParame: forgetPsd
      templatePath: user/ordinary
    - urlParame: iregister
      templatePath: user/admin
    - urlParame: boss
      templatePath: user/boss
  # 系统数据写接口匹配规则(正则表达式)，多个用逗号隔开。后续新增规则直接在此处添加即可
  writeRegx: add.*,save.*,remove.*,update.*,batch.*,clear.*,add.*,append.*,modify.*,edit.*,insert.*,delete.*,do.*,creat.*
security:
  auth:
    user:
      admin:
        name: admin
        password: admin
        roles: SWAGGER,ACTUATOR
      swagger:
        name: swagger
        password: swagger
        roles: SWAGGER
# Actuator 组件
management:
  endpoint:
    health:
      # 健康端点显示信息
      show-details: always
  endpoints:
    web:
      # 健康组件base-path，默认值为：/actuator
      base-path: /actuator
      exposure:
        # 设置健康组件包含端点
        include: info,health,beans,mappings,openapi,swagger-ui
# springdoc 配置
springdoc:
  show-actuator: true
logging:
  level:
    com.jdw.springboot: debug
    org.springframework.security: debug
